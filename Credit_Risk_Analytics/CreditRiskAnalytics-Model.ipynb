{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <h1>CREDIT RISK ANALYTICS</h1>\n",
    "</center>\n",
    "\n",
    "**Background:** Credit  scoring  is  the  set  of  decision  models  and  their  underlying  techniques \n",
    "that  aid  lenders  in  the  granting  of  consumer  credit.  These  techniques determine  who  will  get  credit,  how  much  credit  they  should  get,  and  what operational  strategies  will  enhance  the  profitability  of  the  borrowers  to  the lenders.  Further,  they  help  to  assess  the  risk  in  lending.  Credit  scoring  is  a dependable  assessment  of  a  personâ€™s  credit  worthiness  since  it  is  based  on actual data.\n",
    "\n",
    "#### Definition of Target and Outcome Window:\n",
    "One of the leading banks would like to predict bad customer while customer applying for loan. This model also called as PD Models (Probability of Default)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = 10, 8\n",
    "plt.style.use(\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for machine learning\n",
    "\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing -\n",
    " - Missing Values Treatment - Numerical (Mean/Median imputation) and Categorical (Separate Missing Category or Merging)\n",
    " - Univariate Analysis - Outlier and Frequency Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankloans = pd.read_csv(\"Data/bankloans.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ed</th>\n",
       "      <th>employ</th>\n",
       "      <th>address</th>\n",
       "      <th>income</th>\n",
       "      <th>debtinc</th>\n",
       "      <th>creddebt</th>\n",
       "      <th>othdebt</th>\n",
       "      <th>default</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>176</td>\n",
       "      <td>9.3</td>\n",
       "      <td>11.359392</td>\n",
       "      <td>5.008608</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1.362202</td>\n",
       "      <td>4.000798</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>55</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.856075</td>\n",
       "      <td>2.168925</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>120</td>\n",
       "      <td>2.9</td>\n",
       "      <td>2.658720</td>\n",
       "      <td>0.821280</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>17.3</td>\n",
       "      <td>1.787436</td>\n",
       "      <td>3.056564</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  ed  employ  address  income  debtinc   creddebt   othdebt  default\n",
       "0   41   3      17       12     176      9.3  11.359392  5.008608      1.0\n",
       "1   27   1      10        6      31     17.3   1.362202  4.000798      0.0\n",
       "2   40   1      15       14      55      5.5   0.856075  2.168925      0.0\n",
       "3   41   1      15       14     120      2.9   2.658720  0.821280      0.0\n",
       "4   24   2       2        0      28     17.3   1.787436  3.056564      1.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankloans.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'ed', 'employ', 'address', 'income', 'debtinc', 'creddebt',\n",
       "       'othdebt', 'default'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bankloans.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(850, 9)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#number of observations and features\n",
    "bankloans.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 850 entries, 0 to 849\n",
      "Data columns (total 9 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   age       850 non-null    int64  \n",
      " 1   ed        850 non-null    int64  \n",
      " 2   employ    850 non-null    int64  \n",
      " 3   address   850 non-null    int64  \n",
      " 4   income    850 non-null    int64  \n",
      " 5   debtinc   850 non-null    float64\n",
      " 6   creddebt  850 non-null    float64\n",
      " 7   othdebt   850 non-null    float64\n",
      " 8   default   700 non-null    float64\n",
      "dtypes: float64(4), int64(5)\n",
      "memory usage: 59.9 KB\n"
     ]
    }
   ],
   "source": [
    "#data types in the dataframe\n",
    "bankloans.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>\n",
    "- Checking for missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age         False\n",
       "ed          False\n",
       "employ      False\n",
       "address     False\n",
       "income      False\n",
       "debtinc     False\n",
       "creddebt    False\n",
       "othdebt     False\n",
       "default      True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for any column has missing values\n",
    "bankloans.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check for number of missing values\n",
    "bankloans.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Segregating the numeric and categorical variable names\n",
    "\n",
    "numeric_var_names = [key for key in dict(bankloans.dtypes) if dict(bankloans.dtypes)[key] in ['float64', 'int64', 'float32', 'int32']]\n",
    "catgorical_var_names = [key for key in dict(bankloans.dtypes) if dict(bankloans.dtypes)[key] in ['object']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_var_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data set into two sets - existing customers and new customers\n",
    "\n",
    "bankloans_existing = bankloans.loc[bankloans.default.isnull() == 0]\n",
    "bankloans_new = bankloans.loc[bankloans.default.isnull() == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankloans_existing.describe(percentiles=[.25,0.5,0.75,0.90,0.95])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>\n",
    "    - Checking for Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = \"age\",data=bankloans_existing)\n",
    "plt.title(\"Box-Plot of age\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = \"employ\",data=bankloans_existing)\n",
    "plt.title(\"Box-Plot of employee tenure\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = \"income\",data=bankloans_existing)\n",
    "plt.title(\"Box-Plot of employee income\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = \"debtinc\",data=bankloans_existing)\n",
    "plt.title(\"Box-Plot of employee debt to income ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y = \"creddebt\",data=bankloans_existing)\n",
    "plt.title(\"Box-Plot of Credit to debit ratio\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_minlimit = bankloans_existing[\"income\"].quantile(0.75) + 1.5 * (bankloans_existing[\"income\"].quantile(0.75) - bankloans_existing[\"income\"].quantile(0.25))\n",
    "income_minlimit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def outlier_capping(x):\n",
    "    \"\"\"A funtion to remove and replace the outliers for numerical columns\"\"\"\n",
    "    x = x.clip(upper=x.quantile(0.95))\n",
    "    \n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outlier treatment\n",
    "bankloans_existing = bankloans_existing.apply(lambda x: outlier_capping(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Correlation Matrix\n",
    "bankloans_existing.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualize the correlation using seaborn heatmap\n",
    "\n",
    "sns.heatmap(bankloans_existing.corr(),annot=True,fmt=\"0.2f\",cmap=\"coolwarm\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankloans_existing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankloans_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Indicator variable unique types\n",
    "\n",
    "bankloans_existing['default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankloans_existing['default'].value_counts().plot.bar()\n",
    "plt.xlabel(\"default\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.title(\"Distribution of default\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#percentage of unique types in indicator variable\n",
    "\n",
    "round(bankloans_existing['default'].value_counts()/bankloans_existing.shape[0] * 100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exploratory Analysis\n",
    "- Bivariate Analysis - Numeric(TTest)/ Categorical(Chisquare)\n",
    "- Bivariate Analysis - Visualization\n",
    "- Variable Reduction - Multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## performing the independent t test on numerical variables\n",
    "\n",
    "tstats_df = pd.DataFrame()\n",
    "\n",
    "for eachvariable in numeric_var_names:\n",
    "    tstats = stats.ttest_ind(bankloans_existing.loc[bankloans_existing[\"default\"] == 1,eachvariable],bankloans_existing.loc[bankloans_existing[\"default\"] == 0, eachvariable],equal_var=False)\n",
    "    temp = pd.DataFrame([eachvariable, tstats[0], tstats[1]]).T\n",
    "    temp.columns = ['Variable Name', 'T-Statistic', 'P-Value']\n",
    "    tstats_df = pd.concat([tstats_df, temp], axis=0, ignore_index=True)\n",
    "    \n",
    "tstats_df =  tstats_df.sort_values(by = \"P-Value\").reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tstats_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bi-Variate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BivariateAnalysisPlot(segment_by):\n",
    "    \"\"\"A funtion to analyze the impact of features on the target variable\"\"\"\n",
    "    \n",
    "    fig, ax = plt.subplots(ncols=1,figsize = (10,8))\n",
    "    \n",
    "    #boxplot\n",
    "    sns.boxplot(x = 'default', y = segment_by, data=bankloans_existing)\n",
    "    plt.title(\"Box plot of \"+segment_by)\n",
    "    \n",
    "    \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "BivariateAnalysisPlot(\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BivariateAnalysisPlot(\"ed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BivariateAnalysisPlot(\"employ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BivariateAnalysisPlot(\"address\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BivariateAnalysisPlot(\"income\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BivariateAnalysisPlot(\"debtinc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BivariateAnalysisPlot(\"creddebt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BivariateAnalysisPlot(\"othdebt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi Collinearity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = \"+\".join(bankloans_existing.columns.difference([\"default\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#perform vif\n",
    "\n",
    "a, b = dmatrices(formula_like= 'default ~ ' + features,data=bankloans_existing,return_type=\"dataframe\")\n",
    "vif = pd.DataFrame()\n",
    "\n",
    "vif[\"VIF Factor\"] = [variance_inflation_factor(b.values, i) for i in range(b.shape[1])]\n",
    "vif[\"Features\"] = b.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "----\n",
    "<big>\n",
    "- There are 850 observations and 9 features in the data set\n",
    "- All 9 features are numerical in nature\n",
    "- There are no missing values in the data set\n",
    "- Out of 850 customers data, 700 are existing customers and 150 are new customers\n",
    "- In the 700 existing customers, 517 customers are tagged as non defaulters and remaining 183 are tagged as defaulters\n",
    "- The data is highly imbalanced\n",
    "- From VIF check, found out that the correlation between the variables is within the acceptable limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building and Model Diagnostics\n",
    "\n",
    "   - Logistic Regression\n",
    "   - Decision Tree classifier\n",
    "---\n",
    "**Model Diagnostics**\n",
    "\n",
    "- Train and Test split\n",
    "- Significance of each Variable\n",
    "- Gini and ROC / Concordance analysis\n",
    "- Classification Table Analysis - Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "featurecolumns = bankloans_existing.columns.difference(['default'])\n",
    "featurecolumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train and test split\n",
    "\n",
    "train_X,test_X,train_y,test_y = train_test_split(bankloans_existing[featurecolumns],\n",
    "                                                 bankloans_existing['default'], stratify = bankloans_existing['default'], test_size = 0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(train_y.value_counts()/train_y.shape[0] * 100,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model Building\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_X,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Features and their coefficients\n",
    "\n",
    "coefficient_df =  pd.DataFrame({'Features' : pd.Series(featurecolumns),\n",
    "                        \"Coefficients\" : pd.Series(logreg.coef_[0])})\n",
    "coefficient_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance \n",
    "- Test data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics\n",
    "\n",
    "- Recall: Ratio of the total number of correctly classified positive examples divide to the total number of positive examples. High Recall indicates the class is correctly recognized\n",
    "- Precision: To get the value of precision we divide the total number of correctly classified positive examples by the total number of predicted positive examples. High Precision indicates an example labeled as positive is indeed positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the test cases\n",
    "bankloans_test_pred_log = pd.DataFrame({'actual':test_y, 'predicted': logreg.predict(test_X)})\n",
    "bankloans_test_pred_log = bankloans_test_pred_log.reset_index()\n",
    "bankloans_test_pred_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a confusion matrix\n",
    "\n",
    "cm_logreg = metrics.confusion_matrix(bankloans_test_pred_log.actual,\n",
    "                                    bankloans_test_pred_log.predicted,labels = [1,0])\n",
    "cm_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_logreg,annot=True, fmt=\".2f\", cmap=\"coolwarm\",\n",
    "            xticklabels = [\"Default\", \"Not Default\"] , yticklabels = [\"Default\", \"Not Default\"])\n",
    "plt.title(\"Confusion Matrix for Test data\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#find precision score\n",
    "\n",
    "prec_score = metrics.precision_score(bankloans_test_pred_log.actual, bankloans_test_pred_log.predicted)\n",
    "print(\"Precision score :\", round(prec_score,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the overall accuracy of model\n",
    "\n",
    "acc_score = metrics.accuracy_score(bankloans_test_pred_log.actual,bankloans_test_pred_log.predicted)\n",
    "print(\"Accuracy of model :\", round(acc_score,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankloans_test_pred_log.actual.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(bankloans_test_pred_log.actual, bankloans_test_pred_log.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "-----\n",
    "\n",
    "<big>\n",
    "Overall test accuracy is 80%. But it is not a good measure. There are lot of cases which are default and the model has predicted them as not default. The objective of the model is to identify the customers who will default, so that the bank can intervene and act.This might be the case as the default model assumes people with more than 0.5 probability will not default. \n",
    "</big>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the optimum cutoff value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilty of prediction\n",
    "\n",
    "predict_prob_df = pd.DataFrame(logreg.predict_proba(test_X))\n",
    "predict_prob_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankloans_test_pred_log = pd.concat([bankloans_test_pred_log, predict_prob_df], axis = 1)\n",
    "bankloans_test_pred_log.columns = ['index', 'actual', 'predicted', 'default_0','default_1']\n",
    "\n",
    "bankloans_test_pred_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the auc score\n",
    "\n",
    "auc_score = metrics.roc_auc_score(bankloans_test_pred_log.actual, bankloans_test_pred_log.default_1)\n",
    "round(auc_score,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Draw a roc curve\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(bankloans_test_pred_log.actual, bankloans_test_pred_log.default_1, \n",
    "                                         drop_intermediate= False)\n",
    "\n",
    "\n",
    "plt.plot(fpr, tpr , label = 'ROC curve (area = %0.2f)' % auc_score)\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>\n",
    "- Cutoff would be optimum where specificity and sensitivity would be maximum for the given cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##TPR - Sensitivity\n",
    "##1-FPR - Specificity\n",
    "\n",
    "i = np.arange(len(tpr))\n",
    "\n",
    "roc_like_df = pd.DataFrame({'falsepositiverate' : pd.Series(fpr, index=i),'sensitivity' : pd.Series(tpr, index = i), \n",
    "              'specificity' : pd.Series(1-fpr, index = i),'cutoff' : pd.Series(thresholds, index = i)})\n",
    "roc_like_df['total'] = roc_like_df['sensitivity'] + roc_like_df['specificity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_like_df[roc_like_df['total']==roc_like_df['total'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(figsize=(10,6))\n",
    "plt.scatter(roc_like_df['cutoff'], roc_like_df['sensitivity'], marker='*', label='Sensitivity')\n",
    "plt.scatter(roc_like_df['cutoff'], roc_like_df['specificity'], marker='*', label='Specificity')\n",
    "plt.scatter(roc_like_df['cutoff'], roc_like_df['falsepositiverate'], marker='*', label='FPR')\n",
    "plt.title('For each cutoff, pair of sensitivity and FPR is plotted for ROC')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting with new cut-off probability\n",
    "bankloans_test_pred_log['new_labels'] = bankloans_test_pred_log['default_1'].map( lambda x: 1 if x >= 0.224326 else 0 )\n",
    "\n",
    "bankloans_test_pred_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a confusion matrix\n",
    "\n",
    "cm_logreg = metrics.confusion_matrix(bankloans_test_pred_log.actual,\n",
    "                                    bankloans_test_pred_log.new_labels,labels = [1,0])\n",
    "cm_logreg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_logreg,annot=True, fmt=\".2f\", cmap=\"coolwarm\",\n",
    "            xticklabels = [\"Default\", \"Not Default\"] , yticklabels = [\"Default\", \"Not Default\"])\n",
    "plt.title(\"Confusion Matrix for Test data\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report \n",
    "\n",
    "print(metrics.classification_report(bankloans_test_pred_log.actual,bankloans_test_pred_log.new_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intuitively the ability of the classifier to find all the positive samples\n",
    "\n",
    "recall_score = metrics.recall_score(bankloans_test_pred_log.actual, bankloans_test_pred_log.new_labels)\n",
    "print(\"recall_score:\", round(recall_score , 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the overall accuracy of model\n",
    "\n",
    "acc_score = metrics.accuracy_score(bankloans_test_pred_log.actual,bankloans_test_pred_log.new_labels)\n",
    "print(\"Accuracy of model :\", round(acc_score,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inference\n",
    "-----\n",
    "\n",
    "<big>\n",
    "Even though the overall accuracy of the model is reduced from 80% to 75% by taking optimum cutoff as 0.224, Model performance i.e recall score (ability of the model to find all the positive samples - find all the default customers) has increased from 54% to 89%. The drawback of changing the cutoff value can be seen in drastic drop of precision score (ability of model not to label non default customers as default customers) from 67% to 52%. \n",
    "\n",
    "</big>\n",
    "\n",
    "- We have a choice to make depending on the value we place on the true positives and our tolerance for false postivies, in practical the cutoff values depends on the business decision values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a pipeline for decision tree model\n",
    "\n",
    "pipelines = {\n",
    "    \"dtclass\": make_pipeline(DecisionTreeClassifier(random_state=100))\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To check the accuracy of the pipeline\n",
    "scores = cross_validate(pipelines['dtclass'],train_X,train_y,return_train_score=True)\n",
    "scores['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation and Hyper Parameters Tuning\n",
    "Cross Validation is the process of finding the best combination of parameters for the model by traning and evaluating the model for each combination of the parameters\n",
    "- Declare a hyper-parameters to fine tune the Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree is a greedy alogritum it searches the entire space of possible decision trees. so we need to find a optimum parameter(s) or criteria for stopping the decision tree at some point. We use the hyperparameters to prune the decision tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of tunable hyper parameters for decision tree classifier pipeline\n",
    "\n",
    "pipelines['dtclass'].get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decisiontree_hyperparameters = {\n",
    "    'decisiontreeclassifier__max_depth' : np.arange(3, 10),\n",
    "    'decisiontreeclassifier__max_features' : np.arange(3, 8),\n",
    "    'decisiontreeclassifier__min_samples_split' : np.arange(2, 15),\n",
    "    \"decisiontreeclassifier__min_samples_leaf\" : np.arange(1,3)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree classifier with gini index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit and tune models with cross-validation\n",
    "\n",
    "Now that we have our <code style=\"color:steelblue\">pipelines</code> and <code style=\"color:steelblue\">hyperparameters</code> dictionaries declared, we're ready to tune our models with cross-validation.\n",
    "- We are doing 5 fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a cross validation object from decision tree classifier and it's hyperparameters\n",
    "\n",
    "dtclass_model = GridSearchCV(pipelines['dtclass'],decisiontree_hyperparameters,cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit the model\n",
    "\n",
    "dtclass_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display the best parameters for decision tree model\n",
    "\n",
    "dtclass_model.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#best score for the model\n",
    "dtclass_model.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In Pipeline we can use the string names to get the decisiontreeclassifer\n",
    "\n",
    "dtclass_best_model = dtclass_model.best_estimator_.named_steps['decisiontreeclassifier']\n",
    "dtclass_best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Evaluation\n",
    "- On Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting the test cases\n",
    "bankloans_test_pred_dtclass = pd.DataFrame({'actual':test_y, 'predicted': dtclass_best_model.predict(test_X)})\n",
    "bankloans_test_pred_dtclass = bankloans_test_pred_dtclass.reset_index()\n",
    "bankloans_test_pred_dtclass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a confusion matrix\n",
    "\n",
    "cm_dtclass = metrics.confusion_matrix(bankloans_test_pred_dtclass.actual,\n",
    "                                    bankloans_test_pred_dtclass.predicted,labels = [1,0])\n",
    "cm_dtclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_dtclass,annot=True, fmt=\".2f\",\n",
    "            xticklabels = [\"Default\", \"Not Default\"] , yticklabels = [\"Default\", \"Not Default\"])\n",
    "plt.title(\"Confusion Matrix for Test data\")\n",
    "plt.ylabel(\"True Label\")\n",
    "plt.xlabel(\"Predicted Label\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probabilty of prediction\n",
    "\n",
    "predict_prob_df = pd.DataFrame(dtclass_best_model.predict_proba(test_X))\n",
    "predict_prob_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankloans_test_pred_dtclass = pd.concat([bankloans_test_pred_dtclass, predict_prob_df], axis = 1)\n",
    "bankloans_test_pred_dtclass.columns = ['index', 'actual', 'predicted', 'default_0','default_1']\n",
    "\n",
    "bankloans_test_pred_dtclass.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the auc score\n",
    "\n",
    "auc_score = metrics.roc_auc_score(bankloans_test_pred_dtclass.actual, bankloans_test_pred_dtclass.default_1)\n",
    "round(auc_score,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting the roc curve\n",
    "\n",
    "fpr, tpr, thresholds = metrics.roc_curve(bankloans_test_pred_dtclass.actual, bankloans_test_pred_dtclass.default_1,\n",
    "                                         drop_intermediate=False)\n",
    "\n",
    "plt.plot(fpr, tpr, label = \"ROC Curve (Area = %0.4f)\" % auc_score)\n",
    "plt.plot([1,0],[1,0],'k--')\n",
    "\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.xlabel(\"False Positive Rate or [1 - True Negative Rate]\")\n",
    "\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#find precision score\n",
    "\n",
    "prec_score = metrics.precision_score(bankloans_test_pred_dtclass.actual, bankloans_test_pred_dtclass.predicted)\n",
    "print(\"Precision score :\", round(prec_score,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the overall accuracy of model\n",
    "\n",
    "acc_score = metrics.accuracy_score(bankloans_test_pred_dtclass.actual,bankloans_test_pred_dtclass.predicted)\n",
    "print(\"Accuracy of model :\", round(acc_score,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#classification report\n",
    "\n",
    "print(metrics.classification_report(bankloans_test_pred_dtclass.actual,bankloans_test_pred_dtclass.predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of Decision Tree\n",
    "- Dependencies \n",
    "    - Need to install graphviz (conda install pydot graphviz)\n",
    "    - Set the environment path variable to graphviz folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "from IPython.display import Image\n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus as pdot\n",
    "from io import StringIO\n",
    "import graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#writing the dot data\n",
    "dot_data = StringIO()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the decision tree along with the feature names into a dot file format\n",
    "\n",
    "export_graphviz(dtclass_best_model,out_file=dot_data,filled=True,special_characters=True,rounded=True,\n",
    "                feature_names=train_X.columns.values,class_names = [\"No\",\"Yes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make a graph from dot file\n",
    "\n",
    "graph = pdot.graph_from_dot_data(dot_data.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Business Insights\n",
    "___\n",
    "<big>\n",
    "- Based on the F1-score (harmonic mean of precision and recall), logistic model with f1 score (for positive labels - default customers) of 0.66 is giving better results than decision tree model with f1 score of 0.44. So we will use the logistic regression model to predict the credit worthiness of the customers \n",
    "    \n",
    "-We will Predict the credit risk for remainimg 150 customers using the logistic model with cutoff as 0.224 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#probability for new customers\n",
    "\n",
    "new_cust_prob = pd.DataFrame(logreg.predict_proba(bankloans_new[featurecolumns]))\n",
    "new_cust_prob.columns = [\"prob_default_0\", \"prob_default_1\"]\n",
    "new_cust_prob.index = bankloans_new.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "new_cust_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankloans_new_predicted = pd.concat([bankloans_new,new_cust_prob],axis=1)\n",
    "bankloans_new_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the cutoff value we will predict the default\n",
    "\n",
    "bankloans_new_predicted['predicted_default'] = bankloans_new_predicted[\"prob_default_1\"].apply(lambda x: 1 if x > 0.224 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bankloans_new_predicted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Prediction\n",
    "\n",
    "bankloans_new_predicted.predicted_default.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Prediction\n",
    "\n",
    "bankloans_new_predicted.predicted_default.value_counts().plot.bar()\n",
    "\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Default\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insights\n",
    "---\n",
    "\n",
    "- Out of 150 new customers, model has predicted that 85 customers are not going to default on the bank loan and remaining 65 customes would most likely default on the loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Performance Validation\n",
    "\n",
    "- KS Chart\n",
    "- Lift and Gain Chart\n",
    "\n",
    "we will use the concept of decile analysis for these validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For train data\n",
    "\n",
    "train_predict = pd.DataFrame({'actual': train_y.reset_index(drop = True), \n",
    "                              'prob':  pd.DataFrame(logreg.predict_proba(train_X))[1]})\n",
    "train_predict['predicted'] = train_predict['prob'].apply(lambda x: 1 if x > 0.224 else 0)\n",
    "train_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#For test data\n",
    "\n",
    "test_predict = pd.DataFrame({'actual': test_y.reset_index(drop = True), \n",
    "                              'prob':  pd.DataFrame(logreg.predict_proba(test_X))[1]})\n",
    "test_predict['predicted'] = test_predict['prob'].apply(lambda x: 1 if x > 0.224 else 0)\n",
    "test_predict.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<big>\n",
    "    Split the data into different deciles - train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the train data into different deciles\n",
    "\n",
    "train_predict['Deciles']=pd.qcut(train_predict['prob'],10, labels=False)\n",
    "train_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the test data into different deciles\n",
    "\n",
    "test_predict['Deciles']=pd.qcut(test_predict['prob'],10, labels=False)\n",
    "test_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sumation of deciles for train data\n",
    "\n",
    "train_predict[['Deciles','actual']].groupby(train_predict.Deciles).sum().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sumation of deciles for test data\n",
    "\n",
    "test_predict[['Deciles','actual']].groupby(test_predict.Deciles).sum().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predict[['Deciles','actual']].groupby(train_predict.Deciles).count().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict[['Deciles','actual']].groupby(test_predict.Deciles).count().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KS & Lift, Gain Chart\n",
    "- Training dataset\n",
    "- Testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Training data set\n",
    "Image(filename=\"Images/KS-Traindata.png\",width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Test data set\n",
    "Image(filename=\"Images/KS-Testdata.png\",width=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Lift Chart \n",
    "Image(filename=\"Images/LiftChart.png\",width=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Lift Chart \n",
    "Image(filename=\"Images/GainsChart.png\",width=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "---\n",
    "<big>\n",
    "- Gain chart tells % of targets (events) covered at a given decile level. In the current case, we can say that we can identify 90% of the defaulters who are likely to default on the loan by just analyzing 50% of the total customers.\n",
    "- Lift chart measures how much better one can expect to do with the predictive model comparing without a model. In the current model, cummulative lift for top two deciles is 2.7, means that by selecting 20% of the records based on the model. One can expect 2.7 times the total number of defaulters to be found than the randomly selecting 20% of the data without a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, let's save the winning model.\n",
    "- We need to save your prediction models to file, and then restore them in order to reuse your previous work to: test your model on new data, compare multiple models, or anything else.\n",
    "- Pickle is the standard way of serializing objects in Python.Pickle operation to serialize your machine learning algorithms and save the serialized format to a file.\n",
    "- Later you can load this file to deserialize your model and use it to make new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's save the winning <code style=\"color:steelblue\">Logistic Model</code> object into a pickle file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('OutPutModel/final_model.pkl', 'wb') as f:\n",
    "    pickle.dump(logreg, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some time later...\n",
    " \n",
    "# load the model from disk - use to classify the default customers directly\n",
    "#loaded_model = pickle.load(open('OutPutModel/final_model.pkl', 'rb'))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
